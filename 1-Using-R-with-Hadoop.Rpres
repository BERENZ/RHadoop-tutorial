Introduction to Using R with Hadoop
========================================================
author: Andrie de Vries & Simon Field
date: 2015-07-01, UseR!2015
width: 1680
height: 1050
css: css/custom.css


About us
========================================================

Andrie de Vries
- Set up an independent market research firm in 2009
- Started using R
- Joined Revolution Analytics in 2013
- Author of ggdendro, checkpoint, miniCRAN packages
- Co-author of R for Dummies

***

Simon Field
- Career in high performance databases, including TeraData and Netezza
- Joined Revolution Analytics in 2013
- Responsible for Technical Pre-sales in Europe


Connecting to Azure with your browser
========================================================

http://ra-ldn-cluster-master-02.cloudapp.net:8787

Why Hadoop?
========================================================

![](images/indeed-job-trend-stats.png)

Source: http://www.indeed.com/jobtrends?q=HTML5%2C+hadoop%2C+SAS&l=

Hype central
========================================================
![](images/dilbert-big-data-in-the-cloud)


Is your problem big enough for Hadoop?
================================================

When to use Hadoop?
* Conventional processing tools won’t work on your data
* Your data is really BIG
  - Won’t fit/process in your favourite database/file-system
* Your data is really diverse !
  - Semi-structured – JSON, XML, Logs, Images, Sounds
* You’re a wiz at programming

***
When not to use Hadoop?
* !(When to use Hadoop?)
* You’re in a hurry !


My job is reducing
==================
![](images/xkcd-my-job-is-compiling.png)


Hadoop logical flow
==================
![](images/img-hadoop-logical-flow.png)


Three main components
=====================

Hadoop                         | RHadoop project | github
-------                        | --------------  | ------
HDFS (distributed file system) | rhdfs  | ?
mapreduce (task manager)       | rmr2   | ?
hbase (database management)    | rhbase | ?


MapReduce
============
type: section

MapReduce
=========

A programming abstraction
* Applies to many types of big data calculation

Abstracts messy implementation detail in library
* Implicit parallelisation
* Load balancing
* Reduce data movement
* Robust job / machine failure management

MapReduce solves a generic problem
==================================

* Read a large amount of data
* MAP
* Extract a summary from each record
* Shuffle and sort
* REDUCE
* Aggregate, filter transform


The problem outline is generic – simply implement map and reduce to solve the problem at hand



rmr2
============
type: section

rmr2
============
![](images/img-rmr2.png)

MapReduce in R pseudo-code
==========================

In the mapper, v’ is available as data – no need for an explicit read statement

```{r, eval=FALSE}
mapper <- function(k, v){
  ...
  return(k’, v’)
}
```

In the reducer, all v’ with the same k’ is processed together

```{r, eval=FALSE}
reducer <- function(k’, v’){
  ...
  return(k’’, v’’)
}
```



Testing using the local backend
===============================

* The rmr2 package has a “local” back end, completely implemented in R
* This allows easy (and fast) testing before scaling to the “hadoop” backend

```{r, eval=FALSE}
rmr.options(backend = "local")
rmr.options(backend = "hadoop")
```

Sending data  R <---> Hadoop
============================

* The rmr2 package has 2 convenience functions that allow you to import / export a big.data.object into the R session

```{r, eval=FALSE}
to.dfs()
from.dfs()
```

Using the mapreduce() function
==============================

* Specify the input, map and reduce function
* Optionally, specify output, to persist result in hdfs
* If output = NULL, returns a temporary big.data.object

```{r, eval=FALSE}
x <- mapreduce(input, map, reduce, ...)
x()  # returns the file location
     # of the big.data.object
from.dfs(x) # available in R session
```


Demo 1: A first rmr2 script
===================
type: section

Demo 1
======

```{r demo-1-read, cache=FALSE, include=FALSE}
read_chunk("demo/01-intro-lapply.R")
```

```{r load-packages}
```


Demo 1
======

```{r R}
```

Demo 1
======

```{r rmr}
```


Demo 2: Making use of the key
===================
type: section

Demo 2
======

```{r demo-2-read, cache=FALSE, include=FALSE}
read_chunk("demo/02-intro-tapply.R")
```

```{r R}
```

Demo 2
======

```{r rmr}
```

Demo 2
======

```{r demo-2.3}
```


End
===
type: section

Thank you.
